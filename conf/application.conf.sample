# This is the main configuration file for the application, providing default config-values suited to local development.
# According to the practises desribed on http://12factor.net, any deployment of this app should provide a file
# that overrides values as needed
# ~~~~~


# The application languages
# ~~~~~
####application.langs="en"
# "application.langs is deprecated, use play.i18n.langs instead"
play.i18n.langs = ["en"]


# Evolutions
# ~~~~~
# You can disable evolutions if needed
# evolutionplugin=disabled


# WebSocket configuration
# ~~~~~
# Keep WebSocket connections alive and prevent idle timeouts
play.server.websocket.periodic-keep-alive-max-idle = 30s
play.server.websocket.frame.maxLength = 64k
# Prevent idle timeout from closing WebSocket connections
play.server.http.idleTimeout = 1 hour


akka {
  default-dispatcher.core-pool-size-max = 64
//  debug.receive = on
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
  loglevel = "DEBUG"
}


contexts {
  dataset-harvesting-execution-context {
    fork-join-executor {
      parallelism-max = 3
    }
  }
}


orgId = "brabantcloud"

thesaurus = true
categories = false

# Fuseki
triple-store = "http://127.0.0.1:3033/"
sparql-query-path = "/query"
sparql-update-path = "/update"
graph-store-path = "/data"
graph-store-param = "graph"

# Fuseki Authentication (for Fuseki 4.x+ with access control)
# Leave blank for no authentication (Fuseki 2.x style)
fuseki-username = "admin"
fuseki-password = "pw123"

# Fuseki connection pool settings
fuseki {
  # Connection pool settings for better performance - increased limits for concurrent dataset processing
  maxConnectionsPerHost = 100
  maxConnectionsTotal = 200
  connectionTimeoutMs = 10000
  requestTimeoutMs = 60000
  readTimeoutMs = 120000
}

enableIncrementalHarvest = true

# Harvest retry configuration
narthex.harvest {
  # Interval between retry attempts in minutes (default: 60 = 1 hour)
  retryIntervalMinutes = 60
}

# GraphDB
#triple-store = "http://127.0.0.1:7200/repositories"
#sparql-query-path = ""
#sparql-update-path = "/statements"
#graph-store-path = "/rdf-graphs/service"
#graph-store-param = "graph"

rdfBaseUrl = "http://data.brabantcloud.nl"

# replace this dummy with the actual token from your development Nave instance
naveAuthToken = ""

# Set this to true to use the Nave Bulk APi
####mockBulkApi = false
mockBulkApi = true

# the ip-adress where the development nave can be reached
naveApiUrl = "http://localhost:3000"


# oatuth2 not used...

domains = {
  narthex = "http://localhost:9000"
  nave = "http://localhost:3000"
}


#
# configuration properties for play & play plugins
#
####play.crypto.secret="FAQ8wRZyGtCtTAyd"
play.http.secret.key="changethissosomethingsecret"
####play.application.loader=init.MyApplicationLoader
play.modules.enabled += "init.NarthexBindings"

play.mailer {
  host = "localhost"
}

# Override default filters
# See: https://www.playframework.com/documentation/2.8.x/Filters
play.filters.enabled = ["com.kenshoo.play.metrics.MetricsFilterImpl"]

play.http.parser.maxDiskBuffer = 512000kB // == 250 MB

# Play WS client connection pooling configuration
play.ws {
  # Connection pool settings - increased for concurrent dataset processing
  ahc {
    # Maximum number of connections per host
    maxConnectionsPerHost = 100
    # Maximum total connections
    maxConnectionsTotal = 200
    # Connection timeout
    connectTimeout = 10s
    # Request timeout
    requestTimeout = 60s
    # Read timeout
    readTimeout = 120s
    # Keep alive settings
    keepAlive = true
    # Pool connections
    pooledConnectionIdleTimeout = 30s
    connectionPoolCleanerPeriod = 1s
    # Maximum response content length in bytes (50 MB)
    # This allows OAI-PMH responses with many records to complete
    maxContentLength = 52428800
  }
}

datadog {
  # Settings for datadog monitoring reporter
  enabled = false
  statsdHost = "localhost"
  statsdPort = 8125
  reportingIntervalInSeconds = 10
}

healthchecks {
  fuseki.timeoutMillis = 100
}

# the address[es] that receive a notification when dataset processing succeeds or fails
emailReportsTo = [  ]

sipAppDownloadUrl = "https://github.com/delving/sip-creator/releases/download/sip-creator-v1.2.2/sip-app-1.2.2-exejar.jar"
